name: GCS Deployment

# Controls when the action will run. Triggers the workflow on push or pull request events
# but only for the main branch
on:
  push:
    branches: [ main ]

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "deploy"
  deploy:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v2

    # Setup gcloud CLI
    - uses: google-github-actions/setup-gcloud@v0
      with:
        service_account_email: ${{ secrets.GCP_SA_EMAIL }}
        service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
        project_id: ${{ vars.GCP_PROJECT_ID }}  # Fixed variable reference

    - name: Conditional Upload to GCS
      run: |
        # Create variables for the bucket names
        WORKFLOW_BUCKET=${{ vars.WORKFLOW_BUCKET }}
        DATAFLOW_BUCKET=${{ vars.DATAFLOW_BUCKET }}

        # Loop through all files in the repository, excluding certain directories
        for file in $(find . -type f ! -path './.git/*' ! -path './.github/*' ! -path './*/*.yml' ! -path './*/*.yaml'); do
          echo "Processing file: $file"

          # Check if the file is inside the 'airflow' or 'pyspark' directories
          if [[ "$file" == ./airflow/* ]]; then
            echo "Uploading $file to the Workflow Bucket"
            gsutil cp "$file" $WORKFLOW_BUCKET
          elif [[ "$file" == ./pyspark/* ]]; then
            echo "Uploading $file to the Default Bucket"
            gsutil cp "$file" $DEFAULT_BUCKET
          else
            echo "Skipping $file as it does not match the defined directories"
          fi
        done
